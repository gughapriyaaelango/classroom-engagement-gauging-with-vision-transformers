{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchvision import transforms, datasets\r\n",
        "from torch import optim\r\n",
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import os\r\n",
        "import math\r\n",
        "import pycm"
      ],
      "outputs": [],
      "metadata": {
        "id": "gnATQzpibZUz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# configurations\r\n",
        "path = \"/content/wacv2016-master/dataset\"\r\n",
        "path_dest = \"/content/samples\"\r\n",
        "split = 0.8\r\n",
        "batch_size = 16\r\n",
        "seed = 999\r\n",
        "n_samples = [228, 412, 412]"
      ],
      "outputs": [],
      "metadata": {
        "id": "p0kcq2CcbfBW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "# MobileNetV1\n",
        "# in_channels = 1, n_classes = 3, input_shape = b * 1 * 100 * 100\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, ksize, inCH, outCH, padding=0, stride=1):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv2d = nn.Conv2d(kernel_size=ksize, in_channels=inCH, \n",
        "                        out_channels=outCH, padding=padding, stride=stride)\n",
        "        self.bn = nn.BatchNorm2d(outCH)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv2d(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DepthwiseConv2d(nn.Module):\n",
        "    def __init__(self, ksize, inCH, outCH, padding=0, stride=1):\n",
        "        super(DepthwiseConv2d, self).__init__()\n",
        "        self.dwConv2d = nn.Conv2d(kernel_size=ksize, in_channels=inCH, \n",
        "                            out_channels=inCH, stride=stride, padding=padding, groups=inCH)\n",
        "        self.bn = nn.BatchNorm2d(inCH)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.pointwiseConv2d = BasicConv2d(ksize=1, inCH=inCH, outCH=outCH)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dwConv2d(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pointwiseConv2d(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "    def __init__(self, classes=10):\n",
        "        super(MobileNet, self).__init__()\n",
        "        self.pre_layer = BasicConv2d(ksize=3, inCH=1, outCH=32)\n",
        "        self.Depthwise = nn.Sequential(\n",
        "            DepthwiseConv2d(ksize=3, inCH=32, outCH=64, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=64, outCH=128, stride=2, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=128, outCH=128, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=128, outCH=256, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=256, outCH=256, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=256, outCH=512, stride=2, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=512, outCH=512, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=512, outCH=512, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=512, outCH=512, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=512, outCH=512, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=512, outCH=512, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=512, outCH=1024, stride=2, padding=1),\n",
        "            DepthwiseConv2d(ksize=3, inCH=1024, outCH=1024, padding=1)\n",
        "        )\n",
        "        self.avgpool = nn.AvgPool2d((4, 4))\n",
        "        self.linear = nn.Linear(1024*3*3, classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pre_layer(x)\n",
        "        x = self.Depthwise(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(-1, 3*3*1024)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "outputs": [],
      "metadata": {
        "id": "wjziryQxba_5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# generate samples\n",
        "# use provided samples.zip or run this cell to generate samples from wacv2016-master\n",
        "os.mkdir(path_dest)\n",
        "file_num = []\n",
        "for i in range(1, 4):\n",
        "    j = 0\n",
        "    for file in os.listdir(os.path.join(path, str(i))):\n",
        "        img = Image.open(os.path.join(path, str(i), file))\n",
        "        if j < 412:\n",
        "            if img.size[0] == 100 and img.size[1] == 100 and len(img.size) == 2:\n",
        "                j += 1\n",
        "                img.save(os.path.join(path_dest, \"{}_{}.jpg\".format(i-1, j)))\n",
        "        else:\n",
        "            break\n",
        "    file_num.append(j)\n",
        "print(file_num)"
      ],
      "outputs": [],
      "metadata": {
        "id": "H0MRUiNmzpmg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "# dataset split\n",
        "random.seed(seed)\n",
        "file_list = []\n",
        "for i, n in enumerate(n_samples):\n",
        "  for j in range(n):\n",
        "    file_list.append(\"{}_{}.jpg\".format(i, j+1))\n",
        "random.shuffle(file_list)\n",
        "train_list = file_list[:int(split * len(file_list))]\n",
        "val_list = file_list[int(split * len(file_list)):]"
      ],
      "outputs": [],
      "metadata": {
        "id": "rOuIuhHjjfJT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "# dataset class\n",
        "class WACV2016(Dataset):\n",
        "    def __init__(self, path, file_list):\n",
        "        super().__init__()\n",
        "        self.trans = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.path = path\n",
        "        self.file_names = file_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(os.path.join(self.path, self.file_names[index]))\n",
        "        label = int(self.file_names[index].split(\".\")[0].split(\"_\")[0])\n",
        "        return self.trans(img), label"
      ],
      "outputs": [],
      "metadata": {
        "id": "1-hDScSmbiaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "# ...\n",
        "train_set = WACV2016(path_dest, train_list)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_set = WACV2016(path_dest, val_list)\n",
        "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "model = MobileNet(classes=3)\n",
        "model = model.cuda()\n",
        "citeration = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "pGnmUF3GblRa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "# training\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        image, label = image.cuda(), label.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        # forward\n",
        "        output = model(image)\n",
        "        loss = citeration(output, label.long())\n",
        "        pred = torch.torch.argmax(output, 1)\n",
        "        acc = (pred == label).sum() / batch_size\n",
        "        train_loss += loss.item()\n",
        "        train_acc += acc.cpu().numpy()\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"Epoch: {}  Loss: {}  Acc: {}\".format(\n",
        "        epoch+1, train_loss/len(train_loader), train_acc/len(train_loader)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1  Loss: 1.064754716630252  Acc: 0.4033018867924528\n",
            "Epoch: 2  Loss: 1.0321553327002615  Acc: 0.44339622641509435\n",
            "Epoch: 3  Loss: 1.0092262198340218  Acc: 0.4858490566037736\n",
            "Epoch: 4  Loss: 0.9971757013842745  Acc: 0.5082547169811321\n",
            "Epoch: 5  Loss: 0.9811567079346135  Acc: 0.5129716981132075\n",
            "Epoch: 6  Loss: 0.9661633496014577  Acc: 0.5247641509433962\n",
            "Epoch: 7  Loss: 0.9649738928057113  Acc: 0.5011792452830188\n",
            "Epoch: 8  Loss: 0.9545257338937724  Acc: 0.5153301886792453\n",
            "Epoch: 9  Loss: 0.9407656642625917  Acc: 0.5306603773584906\n",
            "Epoch: 10  Loss: 0.9365216358652655  Acc: 0.535377358490566\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctfVwgApboLl",
        "outputId": "3f359303-cec7-40ac-e8dc-e6ee2799bc5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "# validation\n",
        "model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "for i, (image, label) in enumerate(val_loader):\n",
        "        image, label = image.cuda(), label.cuda()\n",
        "        # forward\n",
        "        output = model(image)\n",
        "        pred = torch.argmax(output, 1).unsqueeze(0)\n",
        "        y_pred.append(int(pred.cpu().numpy()))\n",
        "        y_true.append(int(label.unsqueeze(0).cpu().numpy()))\n",
        "print(y_pred)\n",
        "print(y_true)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 1, 1, 0, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 0, 2, 2, 1, 2, 2, 2, 2, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 0, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 0, 2, 2, 1, 1, 1, 2, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 0]\n",
            "[1, 2, 2, 0, 2, 2, 1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 2, 0, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 0, 2, 0, 1, 0, 1, 2, 1, 2, 2, 1, 1, 0, 2, 2, 1, 1, 0, 1, 1, 2, 1, 2, 2, 1, 2, 2, 0, 0, 2, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 1, 0, 1, 1, 1, 0, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2, 2, 2, 1, 2, 0, 1, 2, 2, 1, 2, 1, 1, 0, 2, 2, 2, 0, 1, 1, 2, 0, 1, 1, 0, 2, 0, 2, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 0, 2, 0, 1, 0, 0, 2, 1, 1, 2, 1, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 0, 2, 1, 0, 2, 0, 2, 2, 1, 2, 2, 0, 1, 2, 1, 1, 2, 1, 0, 1, 0, 2, 1, 2, 1, 0, 1, 1, 1, 0, 2, 1, 2, 2, 0]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3tAIOu_0LTK",
        "outputId": "50b309ef-fef4-4f7e-9aa3-3340cf33c5a8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "cm = pycm.ConfusionMatrix(y_true, y_pred, digit=5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "RSFt3-Wync2g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "cm.ACC"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.8199052132701422, 1: 0.5781990521327014, 2: 0.5781990521327014}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DGEuUgPnrT0",
        "outputId": "7e5a7b08-7dfe-45e1-c6c8-e5d0912b8aaf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "cm.GI"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.23679912901469802, 1: 0.08791832104367558, 2: 0.1941176470588235}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEuJUofMns-6",
        "outputId": "f3cbd10b-5064-4730-ff0e-c7f0003b4419"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "cm.AUC"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.618399564507349, 1: 0.5439591605218378, 2: 0.5970588235294118}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt8nE0hsyfLe",
        "outputId": "b1d41994-c642-416e-a391-60bf4bc01f9a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "cm.AGF"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.5149201703743067, 1: 0.5117645387620399, 2: 0.6459840247571285}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ],
      "metadata": {
        "id": "etvWAYdNnw6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c150a4f-e037-4b26-dfb4-c51a53f6a372"
      }
    }
  ]
}